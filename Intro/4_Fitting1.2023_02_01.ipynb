{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 4: Curve Fitting\n",
    "\n",
    "[v 2023-02-01]\n",
    "Developed by Megan Renz for Cornell Physics Labs. [Adapted by L.A. Bumm 2022-09-16]\n",
    "\n",
    "Reminder: the code cells throughout this tutorial will build off of previous code cells. It is important to run every code cell <SHIFT + ENTER> in the document, in order, up to the point where you are working every time you open this tutorial. If you get an error message (particularly one that says that a particular variable is not defined) after attempting to run a code cell, first make sure that you have run every previous code cell. \n",
    "\n",
    "Oftentimes, we will want to figure out the relationship between two variables, i.e., $x$ and $y$, as a function: $f(x)=y$. The most common question will be if the relationship between $x$ and $y$ is linear; in this case, we need to also figure out what the slope and intercept of that line should be.  \n",
    "\n",
    "Let's say we have some data, which we want to plot as $y$ vs $x$ and find out if the relationship between them is linear.  \n",
    "\n",
    "Below we have a graph where the data are the blue dots and the solid red and dotted green lines show two attempts to fit the data. Run the block below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-01T01:22:46.666345Z",
     "iopub.status.busy": "2023-10-01T01:22:46.665893Z",
     "iopub.status.idle": "2023-10-01T01:22:49.284699Z",
     "shell.execute_reply": "2023-10-01T01:22:49.283078Z",
     "shell.execute_reply.started": "2023-10-01T01:22:46.666216Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#this is some imports you don't need to worry about.  \n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from ipywidgets import *\n",
    "\n",
    "\n",
    "#Again, don't worry too much about this code, just creating an example.  \n",
    "x=np.arange(10)\n",
    "y=np.arange(10)+np.random.random(10)-.5\n",
    "plt.figure()\n",
    "plt.errorbar(x,y, np.ones(10)*.2, fmt='.')\n",
    "plt.plot(x,x,'r', label=\"f(x)=x\")\n",
    "plt.plot(x,.5*x, 'g-.', label=\"f(x)=.5*x\")\n",
    "plt.title(\"y vs x\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Which one of the two lines above seems like a better fit to the data? Please explain your reasoning. (0.5 points)\n",
    "\n",
    "> The **red solid line**, $f(x) = x$, is the better fit as it follows the blue data points more closly then the green dotted line.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the time, the difference between possible fit lines will be a bit more subtle. In these cases, we want to come up with a way to make our goodness-of-fit assessment quantitative instead of qualitative.  To do that, we are going to use our data and our function and come up with a number or \"score\" that tells us if our fit is good or bad.  \n",
    "\n",
    "When the score is small, our fit is good, and when the score is large, our fit is bad.  \n",
    "\n",
    "\n",
    "We want to take several things into account:  \n",
    "\n",
    "1.  The score should increase as the points get further away from the function, by our definition above.\n",
    "2.  We want points with smaller uncertainties to \"count\" more towards the score; if the function is far away from a point with a small uncertainty, our fit is worse than if the function is far away from a point that has large uncertainty.   \n",
    "3.  Our score should not depend on units. That is, we want the score to be dimensionless so we can have a standard way of interpreting a \"good\" or \"bad\" fit, regardless of the units in our data.\n",
    "4.  Our score should not change as we add more points that are similar to the ones we already have. That is, we want a standard way of interpreting a \"good\" or \"bad\" fit, regardless of the number of data points.\n",
    "\n",
    "\n",
    "While there are many ways to assess how well a curve fits data, the method that we will use here is called Chi-Squared (\"chi\" is pronounced like \"sky\", but without the 's'):\n",
    "\n",
    "\n",
    "$$\\chi^2=\\frac{1}{N} \\sum_{i=1}^N \\frac{(f(x_i)-y_i)^2}{\\delta y_i^2}$$\n",
    "\n",
    "where we have data points $(x_1, y_1) ... (x_N, y_N)$ with associated uncertainties $\\delta y_i$, and $f(x_i)$ is the function we are fitting evaluated at $x_i$. In the graph above, the red and green lines are examples of possible functions $f(x)$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Explain how the formula for $\\chi^2$ fulfills the four requirements above. (0.5 points)\n",
    "\n",
    "\n",
    ">1.  The difference of $(f(x_i)-y_i)^2$ defines how the score increases as points get further away, no matter the direction. \n",
    ">2.  Using $\\delta y_i^2$ as the denominator ensures the weight of points with smaller uncertainties is greater than those with significant uncertainty.  \n",
    ">3.  This divides the square of the units by the square of the units and cancels out to ensure a unit-less score. \n",
    ">4.  Using $\\frac{1}{N}$ ensures any number of additional, and similar, points **do not** significantly change the score.\n",
    "\n",
    "\n",
    "\n",
    "$\\chi^2$ is written as a python function below. Run the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-01T01:22:49.287206Z",
     "iopub.status.busy": "2023-10-01T01:22:49.286823Z",
     "iopub.status.idle": "2023-10-01T01:22:49.299699Z",
     "shell.execute_reply": "2023-10-01T01:22:49.297143Z",
     "shell.execute_reply.started": "2023-10-01T01:22:49.287159Z"
    }
   },
   "outputs": [],
   "source": [
    "def chiSquared(x, y, dy, f, args):\n",
    "    '''Function Chi-Squared.  \n",
    "    x, y and dy are numpy arrays, referring to x, y and the uncertainty in y respectively.\n",
    "    f is the function we are fitting. \n",
    "    args are the arguments of the function we have fit.  \n",
    "    '''\n",
    "    return 1/(len(x)-len(args))*np.sum((f(x, args)-y)**2/dy**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Compare the equation for $\\chi^2$ to the equation for $t^{\\prime}$ from the last homework tutorial. In what ways are the equations similar and in what ways are they different? (0.25 points)\n",
    "\n",
    "> The similarities are that they both incorporate the uncertainties in the denominator.\n",
    "\n",
    "> The difference is that the $\\chi^2$ is able to negate outliers with significantly larger uncertainties than other points. While the $t^{\\prime}$ equation measures the difference of the means in relation to their uncertainties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. What might a small $\\chi^2$ value mean? What should count as \"small\"? (0.25 points)\n",
    "\n",
    "> The small $\\chi^2$ score means that the fit is very close to the data. This would be approximately $\\chi^2 \\leq 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. What might a large $\\chi^2$ mean?  What should count as \"large\"? (0.5 points)\n",
    "\n",
    "> A large $\\chi^2$ score means that the fit is **not** good and either the parameters or the best-fit formula itself needs to be changed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Below are a few example functions one can fit.  We will most often be fitting a line. Run the code block below. (You do not need to worry about the details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-01T01:22:49.306039Z",
     "iopub.status.busy": "2023-10-01T01:22:49.305569Z",
     "iopub.status.idle": "2023-10-01T01:22:49.316948Z",
     "shell.execute_reply": "2023-10-01T01:22:49.314570Z",
     "shell.execute_reply.started": "2023-10-01T01:22:49.305994Z"
    }
   },
   "outputs": [],
   "source": [
    "def poly(x, args):\n",
    "    '''\n",
    "    returns the value of the polynomial sum (x**i*args[i])\n",
    "    '''\n",
    "    total=x**0*args[0]\n",
    "    for i in range(1,len(args)):\n",
    "        total+=x**i*args[i]\n",
    "    return total\n",
    "def linear(x, args):\n",
    "    '''\n",
    "    A special case of Poly.  \n",
    "    '''\n",
    "    return args[0]+x*args[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at fitting a line to some data.  \n",
    "\n",
    "Here we have some data of an experiment in which a spring is stretched and the spring's force ($y$) is measured at certain stretching distances ($x$). Run the code below, which will produce two graphs.\n",
    "\n",
    "The first is a graph of the data points (black dots with uncertainty bars) and a fit line (in blue). The second is a *residuals* plot, which shows the difference between $f(x_i)$ (the value of our function at $x_i$) and $y_i$ (the measured data at $x_i$) at each $x_i$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-01T01:22:49.319589Z",
     "iopub.status.busy": "2023-10-01T01:22:49.318669Z",
     "iopub.status.idle": "2023-10-01T01:22:50.043455Z",
     "shell.execute_reply": "2023-10-01T01:22:50.041594Z",
     "shell.execute_reply.started": "2023-10-01T01:22:49.319543Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f454a74fc3ba40b887577783c124a184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='intercept', max=20.0, min=-5.0), FloatSlider(value=1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y=np.array([ 1.36,  3.36,  3.92,  4.11,  3.43,  5.22,\n",
    "  8.29,  8.22, 11.15, 10.86])\n",
    "uncertainty=np.ones(10)\n",
    "uncertainty[4]=4\n",
    "x=np.linspace(1,8,10)\n",
    "\n",
    "def update(intercept=0,slope=1):\n",
    "    fx=linear(x,[intercept, slope])\n",
    "\n",
    "    fig, ax=plt.subplots(1,2, figsize=(8,4))\n",
    "    ax[0].set_title(\"force vs extension\")\n",
    "    line,=ax[0].plot(x,linear(x, [0,1]))\n",
    "    data=ax[0].errorbar(x,y, uncertainty, fmt='.k')\n",
    "    ax[1].set_title(\"residuals\")\n",
    "    residuals=linear(x,[0, 1])-y\n",
    "    res=ax[1].errorbar(x,residuals, uncertainty, fmt='.k')\n",
    "    ax[1].grid(True, which='both')\n",
    "#    plt.show()\n",
    "    \n",
    "    line.set_ydata(fx)\n",
    "    residuals=fx-y\n",
    "    ax[1].cla()\n",
    "    res=ax[1].errorbar(x,residuals, uncertainty, fmt='.k')\n",
    "    ax[1].grid(True, which='both')\n",
    "    ax[1].set_title(\"Residuals\")\n",
    "    ax[1].set_xlabel(\"extension (cm)\")\n",
    "    ax[1].set_ylabel(\"f(x) - y\")\n",
    "    ax[0].set_xlabel(\"extension (cm)\")\n",
    "    ax[0].set_ylabel(\"force (N)\")\n",
    "#    fig.canvas.draw_idle()\n",
    "#    plt.show()\n",
    "    fig.show()       \n",
    "\n",
    "    print(\"chi-squared value:  \")\n",
    "    print(chiSquared(x,y, uncertainty, linear, [intercept, slope]).round(3))\n",
    "interact(update, intercept=(-5, 20, .1), slope=(-1, 10, .1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try adjusting the slope and intercept of the line above using the sliders. Watch how the chi-squared value changes as the line becomes a better or worse fit.\n",
    "\n",
    "You can also adjust the slope and intercept values by clicking the numbers to the right of the sliders and typing in your desired value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. What happens as you change the values for the slope and intercept? (0.5 points)\n",
    "\n",
    "> The best-fit line changes and as a result the $\\chi^2$ score can be changed to find the parameters that create the best fit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. What values for the slope and intercept give the smallest value of $\\chi^2$ (to the first decimal place)? (0.5 points)\n",
    "\n",
    "> $Intercept=0.4$ & $slope=1.3$, yields what I found to be the smallest $\\chi^2$ score of $0.762$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. How confident are you that the line you fit is a good representation of the underlying phenomena? (One way to check this is to see if any other lines look like better fits, qualitatively.) (0.5 points)\n",
    "\n",
    "> The line of $Intercept=0.4$ & $slope=1.4$ looks like it could be a slightly better fit qualitatively. However, I am pretty confident that my original best-fit line is a good representation of the phenomena."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This brings us to another question - what if our $\\chi^2$ is really small?  (This is a rhetorical question).  Run the code block below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-01T01:22:50.046067Z",
     "iopub.status.busy": "2023-10-01T01:22:50.045588Z",
     "iopub.status.idle": "2023-10-01T01:22:50.765669Z",
     "shell.execute_reply": "2023-10-01T01:22:50.763693Z",
     "shell.execute_reply.started": "2023-10-01T01:22:50.046019Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f62b47e6f26f423bb732b8b66664db97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='intercept', max=12.0, min=-5.0, step=0.2), FloatSlid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "largeUncertainty=uncertainty*5\n",
    "\n",
    "def update(intercept=0,slope=1):\n",
    "    fig, ax=plt.subplots(1,2, figsize=(8,4))\n",
    "    ax[0].set_title(\"force vs extension\")\n",
    "    line,=ax[0].plot(x,linear(x, [0,1]))\n",
    "    data=ax[0].errorbar(x,y, largeUncertainty, fmt='.k')\n",
    "    ax[1].set_title(\"residuals\")\n",
    "    residuals=linear(x,[0, 1])-y\n",
    "    res=ax[1].errorbar(x,residuals, largeUncertainty, fmt='.k')\n",
    "    ax[1].grid(True, which='both')\n",
    "    #plt.show()\n",
    "    fx=linear(x,[intercept, slope])\n",
    "    line.set_ydata(fx)\n",
    "    residuals=fx-y\n",
    "    ax[1].cla()\n",
    "    res=ax[1].errorbar(x,residuals, largeUncertainty, fmt='.k')\n",
    "    ax[1].set_title(\"residuals\")\n",
    "    ax[1].grid(True, which='both')\n",
    "   # fig.canvas.draw_idle()\n",
    "    fig.show()\n",
    "    print(\"chi-squared value:  \")\n",
    "    print(chiSquared(x,y, largeUncertainty, linear, [intercept, slope]).round(3))\n",
    "interact(update, intercept=(-5, 12, .2), slope=(0, 5, .1));\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you should have a large range of values for which the $\\chi^2$ value is quite small. For example, a fit with intercept=-4.6 and slope=2.2 and one with intercept=3.2 and slope=.6 both give $\\chi^2$ values around 0.2. *Reminder:  You can enter values into the boxes next to the sliders!*\n",
    "\n",
    "\n",
    "### 9. How confident are you that either of these sets of fit parameters are a good representation of the underlying phenomena?  Do you trust them?  (0.5 points)\n",
    "\n",
    "\n",
    "> I am fairly confident that first set, intercept=-4.6 and slope=2.2, is a decent best-fit. However, the intercept=3.2 and slope=.6 line does not appear to be near any points even though the $\\chi^2$ value is around 0.2. I trust the first set but not the latter. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your $\\chi^2$ is too small (e.g. $\\chi^2 <<1$), you may have overestimated your uncertainties. That is, your fit is telling you that you measured these data points much more precisely than you thought! Uncertainty overestimation is a problem because it means that it is hard to identify which of the lines that appear to be a good fit actually reflect the underlying physics.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 10. What do you think you should do if you obtain a very small $\\chi^2$ value? (0.5 points)\n",
    "\n",
    "> The best-fit line should be examined along with the uncertainties as there could be errors in overestimating the uncertainties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A $\\chi^2$ value larger than 9 is considered a very poor fit for the data. (Why 9?) \n",
    "\n",
    "For $\\chi^2$, there are a few possible outcomes:  \n",
    "\n",
    "1. $\\chi^2\\approx1$\n",
    "2.  $\\chi^2<<1$\n",
    "3.  $1\\lesssim\\chi^2<9$\n",
    "4.  $\\chi^2 >9$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Write down different interpretations for what each of these $\\chi^2$ values could mean, and what you should do in each case.  *Hint: refer to the interpretations of values of $t^\\prime$ from the previous tutorial.* (1 point)\n",
    "\n",
    "> 1. The best-fit line should be examined to see if it is also qualitatively representing the data. If this is the case then this would be a **good** best-fit line. If **not** the parameters could be adjusted to find a better fit. \n",
    "\n",
    "> 2. The best-fit line should be examined along with the uncertainties as there could be errors in overestimating the uncertainties. The experimenter could also re-examine measurement procedures for errors to ensure uncertainties are correct. \n",
    "\n",
    "> 3. The best-fit line parameters could be adjusted in order to find a better fit, but if the $\\chi^2$ score is still close to $1$ then the line could still qualitatively represent the data accurately. \n",
    "\n",
    "> 4. The best-fit line parameters **need** to be adjusted in order to find a better fit.\n",
    "\n",
    "\n",
    "#### <span style='color:Red'>*You should never manipulate your uncertainties to obtain a specific $\\chi^2$ value. Your uncertainties should always reflect your real measurements.*</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's investigate the graph called \"Residuals\".  This is a graph of $f(x_i)-y_i$, the difference between what our fit predicts and what we actually got during the experiment.  The x-axis is the same as the graph \"force vs. extension\", but the y-axis is the vertical distance between the line and points. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Given how you expect points to be distributed around the line, what do you expect to see in your residuals graph, if $f(x_i)$ is a good fit? (1 point)\n",
    "\n",
    "> The residuals in the graph should be close to zero if the line is a **good** fit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the residuals graph is a good way to tell if you are trying to fit the right kind of function. The $\\chi^2$  value does not necessarily tell the whole story.\n",
    "\n",
    "Run the code below, and adjust the slider to slope=5, intercept=-17."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "While the $\\chi^2$ value tells us that this fit is bad (large $\\chi^2$), the residual graph can give us an idea about *why*. In this case, the residuals show a linear trend and tells us that the first half of the data points are systematically above the line and the second half are systematically below the line. This should clearly suggest that you should change the slope of the line!\n",
    "\n",
    "Let's try another example.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-01T01:22:50.768356Z",
     "iopub.status.busy": "2023-10-01T01:22:50.767939Z",
     "iopub.status.idle": "2023-10-01T01:22:51.509568Z",
     "shell.execute_reply": "2023-10-01T01:22:51.507906Z",
     "shell.execute_reply.started": "2023-10-01T01:22:50.768308Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebdb58b04a814a22a885af2948b36308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=-17.0, description='intercept', max=20.0, min=-20.0), FloatSlider(valu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y=np.array([ 1.36,  3.36,  3.92,  4.21,  5.43,  6.22,\n",
    "  8.29,  8.22, 10.15, 10.86])\n",
    "y=.5*(y-2)**2\n",
    "uncertainty=np.ones(10)\n",
    "uncertainty[4]=4\n",
    "x=np.linspace(1,8,10)\n",
    "\n",
    "\n",
    "def update(intercept=-17,slope=5):\n",
    "    fig, ax=plt.subplots(1,2, figsize=(8,4))\n",
    "    ax[0].set_title(\"force vs extension\")\n",
    "    line,=ax[0].plot(x,linear(x, [0,1]))\n",
    "    data=ax[0].errorbar(x,y, uncertainty, fmt='.k')\n",
    "    ax[1].set_title(\"residuals\")\n",
    "    residuals=linear(x,[0, 1])-y\n",
    "    res=ax[1].errorbar(x,residuals, uncertainty, fmt='.k')\n",
    "    ax[1].grid(True, which='both')\n",
    "    #plt.show()\n",
    "    \n",
    "    fx=linear(x,[intercept, slope])\n",
    "    line.set_ydata(fx)\n",
    "    residuals=fx-y\n",
    "    ax[1].cla()\n",
    "    res=ax[1].errorbar(x,residuals, uncertainty, fmt='.k')\n",
    "    ax[1].grid(True, which='both')\n",
    "    ax[1].set_title(\"Residuals\")\n",
    "    ax[0].set_xlabel(\"extension (cm)\")\n",
    "    ax[0].set_ylabel(\"force (N)\")\n",
    "    #fig.canvas.draw_idle()\n",
    "    fig.show()\n",
    "    print(\"chi-squared value:  \")\n",
    "    print(chiSquared(x,y, uncertainty, linear, [intercept, slope]).round(3))\n",
    "interact(update, intercept=(-20, 20, .1), slope=(-1, 10, .1));\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the residuals show an upside down \"v\".\n",
    "\n",
    "### 13. What do you think this shape of residuals might suggest about your fit? How might you change the function to get a better fit? (0.5 points)\n",
    "\n",
    "> The residuals show that the equation of the line may be wrong. In this case, it seems that a curved fit would be better, possibly an exponential growth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's practice writing your own code to fit a function to some data manually below.  \n",
    "\n",
    "For example, let's say you stretch a string to the same extension multiple times and measure the force required each time.  \n",
    "\n",
    "First, I have created some sample data, which is 10 extensions (in cm) of the spring (stored in x), and a matrix of 10 rows and 5 columns, where each row is the forces (in N) measured for 5 trials.  \n",
    "\n",
    "Each of the 10 rows corresponds to one of the extension values, in order. Notice that as extension increases, force increases. Within each row, there is no clear trend because each row displays the same measurement taken five times at that extension. \n",
    "\n",
    "### 14. Print out the measurements of the extensions and forces in a matrix. Why are the number of values in \"extensions\" equal to the number of rows in \"forces\"? What are the units of all the values in \"extensions\"? What are the units of all the values in \"forces\"? (1.5 points)\n",
    "\n",
    "> The extensions vary over each row, which is why their numbers coincide. Similarly, each column represents the separate trials. \n",
    "\n",
    "> The units of the extensions are centimeters & the units of the forces are Newtons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-01T01:22:51.511867Z",
     "iopub.status.busy": "2023-10-01T01:22:51.511425Z",
     "iopub.status.idle": "2023-10-01T01:22:51.527112Z",
     "shell.execute_reply": "2023-10-01T01:22:51.525270Z",
     "shell.execute_reply.started": "2023-10-01T01:22:51.511820Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extensions: \n",
      " [0. 1. 2. 3. 4. 5. 6. 7. 8. 9.]\n",
      "forces: \n",
      " [[ 9.49152548e-01  1.74822581e-02 -4.61195102e-01 -1.61286915e-01\n",
      "   9.37015009e-03]\n",
      " [ 1.08770208e+00  7.30887620e-01  1.17259135e+00  1.13696984e+00\n",
      "   6.49775834e-01]\n",
      " [ 1.60778807e+00  2.68870462e+00  1.49872009e+00  2.30910284e+00\n",
      "   1.21743038e+00]\n",
      " [ 2.29404738e+00  2.71765346e+00  3.92459921e+00  3.20251754e+00\n",
      "   3.75045394e+00]\n",
      " [ 4.30864542e+00  3.62434595e+00  4.10316113e+00  3.57729680e+00\n",
      "   3.00239721e+00]\n",
      " [ 4.74216815e+00  5.65256847e+00  5.49725704e+00  5.12717378e+00\n",
      "   5.20947309e+00]\n",
      " [ 5.71712700e+00  6.67007795e+00  5.77063580e+00  5.96652788e+00\n",
      "   5.92960410e+00]\n",
      " [ 6.49506753e+00  6.23950526e+00  7.46682713e+00  6.78357611e+00\n",
      "   6.92063947e+00]\n",
      " [ 7.55887648e+00  7.91509251e+00  7.36043754e+00  8.32319239e+00\n",
      "   6.98798852e+00]\n",
      " [ 9.13480230e+00  8.03403596e+00  9.59581195e+00  9.78619953e+00\n",
      "   8.87804449e+00]]\n"
     ]
    }
   ],
   "source": [
    "extensions=np.linspace(0,9, 10)\n",
    "forces=np.random.normal(0,.5,size=(5,10))\n",
    "forces=forces+extensions[None,:]\n",
    "forces=forces.T\n",
    "\n",
    "print(\"extensions: \\n\", extensions)\n",
    "print(\"forces: \\n\",forces)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not want to plot all 50 data points in the table above. Instead, we want to average the 5 data points for each extension, so that we are only plotting 10 data points (with a clear trend). The uncertainty in the mean should be used to make the errorbars.  \n",
    "\n",
    "As a hint, take a look at the code below:  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-01T01:22:51.529309Z",
     "iopub.status.busy": "2023-10-01T01:22:51.528938Z",
     "iopub.status.idle": "2023-10-01T01:22:51.557131Z",
     "shell.execute_reply": "2023-10-01T01:22:51.555040Z",
     "shell.execute_reply.started": "2023-10-01T01:22:51.529266Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]\n",
      " [5 1]]\n",
      "summing over axis=0:\n",
      "[9 7]\n",
      "summing over axis=1:\n",
      "[3 7 6]\n"
     ]
    }
   ],
   "source": [
    "numpyExample=np.array([[1,2],[3,4], [5,1]])\n",
    "print(numpyExample)\n",
    "print(\"summing over axis=0:\")\n",
    "print(np.sum(numpyExample, axis=0))\n",
    "print(\"summing over axis=1:\")\n",
    "print(np.sum(numpyExample, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: When using functions in *numpy*, you can specify whether you want to take the average across the row or the column using <span style='font-family:Courier'>axis = 1</span> or <span style='font-family:Courier'>axis = 0</span> respectively.  This also works for <span style='font-family:Courier'>np.sum</span> and other functions.\n",
    "\n",
    "\n",
    "\n",
    "We will need to average the five trials together for each extension of the spring, and put that in $y$, and find the uncertainty in the force measurement for each extension of the spring, and put that in $dy$. \n",
    "\n",
    "Your final answer for both $y$ and $dy$ should be a vector of length 10.  \n",
    "\n",
    "### 15. Fill in the three '...' below to create an array for the mean force measurements for each extension of the spring, $y$, and their uncertainties, $dy$.  (1.5 points)\n",
    "  \n",
    "[1.] Check that *y* and *dy* are what you expect (particularly check the number of data points). \n",
    "> Yes as there are 10 values for each extension in both y & dy. \n",
    "\n",
    "[2.] Manually check the first value (corresponding to extension=0 for each). \n",
    "\n",
    "> Manually taking the values for and checking by hand shows this is correct:\n",
    "\\begin{align*}\n",
    " \\text{For extension=0  }:& -0.25329851,  0.92804241,  0.22524116, -0.83976684, -0.2905438\\\\\n",
    " \\\\\n",
    " mean =& \\frac{-0.25329851+  0.92804241+  0.22524116+ -0.83976684+ -0.2905438}{5}\\\\\n",
    " \\\\\n",
    " &mean = -0.04606511600000003\\\\\n",
    " \\\\\n",
    " & \\sigma = 0.5924813078581521 \\text{ found using code} \\\\\n",
    " \\\\\n",
    " & \\text{standard uncertainty of the mean} = \\frac{0.59248130}{\\sqrt{5}}\\\\\n",
    " \\\\\n",
    " & \\text{standard uncertainty of the mean} = 0.2649656924394892\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-01T01:22:51.559577Z",
     "iopub.status.busy": "2023-10-01T01:22:51.559187Z",
     "iopub.status.idle": "2023-10-01T01:22:51.574182Z",
     "shell.execute_reply": "2023-10-01T01:22:51.571933Z",
     "shell.execute_reply.started": "2023-10-01T01:22:51.559532Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5924813078581521"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check = np.array([-0.25329851,  0.92804241,  0.22524116, -0.83976684, -0.2905438])\n",
    "np.std(check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-01T01:22:51.576438Z",
     "iopub.status.busy": "2023-10-01T01:22:51.576064Z",
     "iopub.status.idle": "2023-10-01T01:22:51.592415Z",
     "shell.execute_reply": "2023-10-01T01:22:51.590277Z",
     "shell.execute_reply.started": "2023-10-01T01:22:51.576395Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y:\n",
      "[0.07070459 0.95558534 1.8643492  3.17785431 3.7231693  5.24572811\n",
      " 6.01079455 6.7811231  7.62911749 9.08577885]\n",
      "dy:\n",
      "[0.21118738 0.0982762  0.24457145 0.27415368 0.20373839 0.14109969\n",
      " 0.15324789 0.18599339 0.20510395 0.27585814]\n"
     ]
    }
   ],
   "source": [
    "y=np.mean(forces, axis=1) #Take the mean of each of the sets of 5 trials in \"forces\".  \n",
    "\n",
    "#Note: When using functions in numpy, you can specify whether you want to take the average across the row or the \n",
    "#column using axis= 1 or 0 respectively.  This also works for np.sum and other functions.\n",
    "\n",
    "print(\"y:\")\n",
    "print(y)\n",
    "dy=np.std(forces, axis=1)/np.sqrt(forces.shape[1]) #Calculate the standard uncertainty of the mean for each of the sets of 5 trials in \"forces\". \n",
    "#divide by square root of number of trials in each set to get the uncertainty.  \n",
    "print(\"dy:\")\n",
    "print(dy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot what we just made, and try fitting it. Run the code block below. \n",
    "\n",
    "> A **good** best-fit line was found with intercept:-1.0 & slope: 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-01T01:22:51.594524Z",
     "iopub.status.busy": "2023-10-01T01:22:51.594151Z",
     "iopub.status.idle": "2023-10-01T01:22:52.274042Z",
     "shell.execute_reply": "2023-10-01T01:22:52.272099Z",
     "shell.execute_reply.started": "2023-10-01T01:22:51.594481Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb44de421fb44eeca471bd6a3ae17412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='intercept', max=12.0, min=-2.0, step=0.2), FloatSlid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "uncertainty=dy \n",
    "def update(intercept=0,slope=1):\n",
    "    \n",
    "    fig, ax=plt.subplots(1,2, figsize=(8,4))\n",
    "    ax[0].set_title(\"force vs extension\")\n",
    "    line,=ax[0].plot(x,linear(x, [0,1]))\n",
    "    data=ax[0].errorbar(x,y, uncertainty, fmt='.k')\n",
    "    ax[1].set_title(\"residuals\")\n",
    "    residuals=linear(x,[0, 1])-y\n",
    "    res=ax[1].errorbar(x,residuals, uncertainty, fmt='.k')\n",
    "    ax[1].grid(True, which='both')\n",
    "    #plt.show()\n",
    "    \n",
    "    fx=linear(x,[intercept, slope])\n",
    "    line.set_ydata(fx)\n",
    "    residuals=fx-y\n",
    "    ax[1].cla()\n",
    "    res=ax[1].errorbar(x,residuals, uncertainty, fmt='.k')\n",
    "    ax[1].grid(True, which='both')\n",
    "    ax[1].set_title(\"Residuals\")\n",
    "    #fig.canvas.draw_idle()\n",
    "    fig.show()\n",
    "    print(\"chi-squared value:  \")\n",
    "    print(chiSquared(x,y, uncertainty, linear, [intercept, slope]).round(3))\n",
    "interact(update, intercept=(-2, 12, .2), slope=(0, 5, .1));\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save your notebook with all your answers to the questions, modified code cells, and output from each code cell. Submit your notebook by uploading it to the Canvas assignment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (py39)",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
